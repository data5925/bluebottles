# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tg0nuNMQp4S9VhQhqHvr1NWgmX3xn0G_
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve
from sklearn.utils.class_weight import compute_class_weight
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input
from tensorflow.keras.callbacks import EarlyStopping


df = pd.read_csv("final_data.csv")
df['time'] = pd.to_datetime(df['time'])
df = df.sort_values("time").reset_index(drop=True)

# Add time-based features
df['month'] = df['time'].dt.month
df['dayofweek'] = df['time'].dt.dayofweek


# Define multiple feature combinations to try
feature_sets = [
    ['crt_u', 'wave_hs', 'wnd_dir', 'month', 'dayofweek'],
    ['crt_temp', 'crt_salt', 'wave_dir', 'wnd_dir', 'month', 'dayofweek'],
    ['crt_temp', 'wave_dir', 'wave_hs', 'wave_fp', 'month', 'dayofweek'],
    ['crt_temp', 'wave_dir', 'wnd_dir', 'wave_t01', 'wave_fp', 'month', 'dayofweek'],
    ['crt_temp', 'crt_u', 'crt_v', 'wave_dir', 'wave_hs', 'wave_t01', 'wave_fp', 'wnd_dir', 'month', 'dayofweek']
]

# LSTM
def run_lstm_experiment(df, feature_list, seq_len=14):
    print(f"\n Running experiment with features:\n{feature_list}\n")

    # Time-based split
    split_index = int(len(df) * 0.8)
    df_train = df.iloc[:split_index].copy()
    df_test = df.iloc[split_index:].copy()

    # Scale features
    scaler = MinMaxScaler()
    df_train_scaled = df_train.copy()
    df_test_scaled = df_test.copy()
    df_train_scaled[feature_list] = scaler.fit_transform(df_train[feature_list])
    df_test_scaled[feature_list] = scaler.transform(df_test[feature_list])

    # Create sequences
    def create_sequences(data, labels, seq_len):
        X, y = [], []
        for i in range(len(data) - seq_len):
            X.append(data[i:i+seq_len])
            y.append(labels[i+seq_len])
        return np.array(X), np.array(y)

    X_train, y_train = create_sequences(df_train_scaled[feature_list].values, df_train_scaled['presence'].values, seq_len)
    X_test, y_test = create_sequences(df_test_scaled[feature_list].values, df_test_scaled['presence'].values, seq_len)

    # Class weights
    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
    class_weights_dict = dict(enumerate(class_weights))

    # Build Bidirectional LSTM
    model = Sequential([
        Input(shape=(seq_len, len(feature_list))),
        Bidirectional(LSTM(50, activation='tanh')),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    early_stop = EarlyStopping(patience=10, restore_best_weights=True)

    history = model.fit(X_train, y_train, validation_split=0.1, epochs=50, batch_size=16,
                        class_weight=class_weights_dict, callbacks=[early_stop], verbose=0)

    # Predict and evaluate
    y_pred_prob = model.predict(X_test).flatten()

    for threshold in [0.5, 0.6, 0.7, 0.8]:
        print(f"\n Threshold = {threshold}")
        y_pred = (y_pred_prob > threshold).astype(int)
        print(classification_report(y_test, y_pred, digits=3))
        print("Confusion Matrix:")
        print(confusion_matrix(y_test, y_pred))

    # ROC Curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(6, 4))
    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
    plt.plot([0, 1], [0, 1], linestyle='--')
    plt.title("ROC Curve")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.legend()
    plt.grid(True)
    plt.show()

    # PR Curve
    precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)
    plt.figure(figsize=(6, 4))
    plt.plot(recall, precision)
    plt.title("Precision-Recall Curve")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.grid(True)
    plt.show()

# Loop over feature sets
for idx, feature_list in enumerate(feature_sets):
    print(f"\n=======================\n Trial {idx + 1} of {len(feature_sets)}\n=======================\n")
    run_lstm_experiment(df, feature_list)

"""Best Model: Trial 5 at Threshold 0.6
- Highest recall (0.370) — catching 37% of actual presences

- Best F1-score (0.146) — overall best balance

- Precision is low but expected in rare-event prediction

- Reasonable accuracy (~70%)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve
from sklearn.utils.class_weight import compute_class_weight
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input
from tensorflow.keras.callbacks import EarlyStopping

# Load and preprocess data
df = pd.read_csv("final_data.csv")
df['time'] = pd.to_datetime(df['time'])
df = df.sort_values("time").reset_index(drop=True)

# Add time-based features
df['month'] = df['time'].dt.month
df['dayofweek'] = df['time'].dt.dayofweek

# Feature sets to test
feature_sets = [
    ['crt_u', 'wave_hs', 'wnd_dir', 'month', 'dayofweek'],
    ['crt_temp', 'crt_salt', 'wave_dir', 'wnd_dir', 'month', 'dayofweek'],
    ['crt_temp', 'wave_dir', 'wave_hs', 'wave_fp', 'month', 'dayofweek'],
    ['crt_temp', 'wave_dir', 'wnd_dir', 'wave_t01', 'wave_fp', 'month', 'dayofweek'],
    ['crt_temp', 'crt_u', 'crt_v', 'wave_dir', 'wave_hs', 'wave_t01', 'wave_fp', 'wnd_dir', 'month', 'dayofweek']
]

# LSTM experiment function with Vanilla LSTM
def run_lstm_experiment(df, feature_list, seq_len=14):
    print(f"\n Running Vanilla LSTM experiment with features:\n{feature_list}\n")

    # Time-based train/test split
    split_index = int(len(df) * 0.8)
    df_train = df.iloc[:split_index].copy()
    df_test = df.iloc[split_index:].copy()

    # Normalize features
    scaler = MinMaxScaler()
    df_train_scaled = df_train.copy()
    df_test_scaled = df_test.copy()
    df_train_scaled[feature_list] = scaler.fit_transform(df_train[feature_list])
    df_test_scaled[feature_list] = scaler.transform(df_test[feature_list])

    # Sequence creation
    def create_sequences(data, labels, seq_len):
        X, y = [], []
        for i in range(len(data) - seq_len):
            X.append(data[i:i+seq_len])
            y.append(labels[i+seq_len])
        return np.array(X), np.array(y)

    X_train, y_train = create_sequences(df_train_scaled[feature_list].values, df_train_scaled['presence'].values, seq_len)
    X_test, y_test = create_sequences(df_test_scaled[feature_list].values, df_test_scaled['presence'].values, seq_len)

    # Compute class weights
    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
    class_weights_dict = dict(enumerate(class_weights))

    # Define Vanilla LSTM model
    model = Sequential([
        Input(shape=(seq_len, len(feature_list))),
        LSTM(50, activation='tanh'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    early_stop = EarlyStopping(patience=10, restore_best_weights=True)

    # Train model
    history = model.fit(X_train, y_train, validation_split=0.1, epochs=50, batch_size=16,
                        class_weight=class_weights_dict, callbacks=[early_stop], verbose=0)

    # Predict probabilities
    y_pred_prob = model.predict(X_test).flatten()

    # Evaluate with thresholds
    for threshold in [0.5, 0.6, 0.7, 0.8]:
        print(f"\n Threshold = {threshold}")
        y_pred = (y_pred_prob > threshold).astype(int)
        print(classification_report(y_test, y_pred, digits=3))
        print("Confusion Matrix:")
        print(confusion_matrix(y_test, y_pred))

    # ROC Curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(6, 4))
    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
    plt.plot([0, 1], [0, 1], linestyle='--')
    plt.title("ROC Curve")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.legend()
    plt.grid(True)
    plt.show()

    # PR Curve
    precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)
    plt.figure(figsize=(6, 4))
    plt.plot(recall, precision)
    plt.title("Precision-Recall Curve")
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.grid(True)
    plt.show()

# Run trials for all feature combinations
for idx, feature_list in enumerate(feature_sets):
    print(f"\n=======================\n Trial {idx + 1} of {len(feature_sets)}\n=======================\n")
    run_lstm_experiment(df, feature_list)

"""Trial 1 (Threshold 0.5): Highest recall (0.543) for presence

Trial 5 (Threshold 0.6): Best overall balance with reasonable recall (0.152), highest accuracy (0.833), and few false positives

Trial 2 (Threshold 0.6): Competitive with recall 0.261 and solid F1 for class 0

Trial 1 best for high recall

Trial 5 most balanced
"""

